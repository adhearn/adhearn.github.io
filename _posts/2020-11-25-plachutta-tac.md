---
layout: post
title: "Plachutta: A Three-Address Code Intepreter"
---
## Why Bother With Intermediate Representations?
Compilers translate from one formal language to another without changing the meaning of the program. While it’s possible to translate directly from one language to another, it’s often convenient to translate to a series of intermediate languages on the way to the target language. Having lots of passes can be a big advantage. First, it makes the individual passes simple, or at least as simple as possible. Second, it makes it trivial to add optimization passes. Compiler optimizations generally don’t change the input or output languages - if they did, they wouldn’t be optimizations. If you come up with a cool new optimization, it’s easy to add it, since it won’t change the passes before or after, since it doesn’t actually change the language! Third, for novices such as myself it offers lots of convenient places to insert testing. Instead of testing a single, large compiler, I can decompose the problem into implementing and testing several smaller compilers.

To that end, I’ve started working on [Plachutta], an interpreter for a specific intermediate representation called Three-Address Code.

## Three-Address Code
Three-Address Code (TAC, or 3AC) is a fairly simple intermediate representation. It looks a lot like a more convenient assembly code. Here’s a program that calculates 5 factorial and stores the result in a variable named `result`:

```
n = 5
product = 1
loopbegin: if n == 0 jump loopend
product = product * n
n = n - 1
jump loopbegin
loopend: result = product
```

This is a pretty basic example, but it should give a feel for the level of the language - somewhere between C and assembly. Many high-level features, like loops, structs, and multi-part conditionals, have been removed, and the control flow is much more like assembly. However, there’s nothing machine-specific about memory details, function calls are removed from direct stack manipulation, and there are an unlimited number of variables.

Conveniently, it’s pretty simple to write an interpreter for a language like this. With one instruction per line, no loops, and explicit jumps, it’s a very basic language. In general, my experience has been that compilers start complicated, as you deal with all the complexity of the source language. Presumably, that language has lots of features, which is why you want to use it. As the compiler does its work, it tends to produce simpler and simpler representations. However, eventually that simplification reverses, once the compiler has to begin thinking about details of the target language - things like how to allocate the 734 distinct variable names you used in your program to just 16 general purpose registers, or how to choose just the optimal multiplication instruction. In the end, you get something like an hourglass shape of complexity. TAC sits near the narrowest bit of this hourglass-shaped complexity.

## Plachutta’s Grammar and Architecture
The specific TAC language used by Plachutta is formally defined by an ANTLR grammar, but at its simplest is just a file of instructions, one instruction per line. Each instruction can have zero or more labels, and in the initial implementation can either be an assignment (like `x = 5` or `x = y + z`), a jump (either unconditional, like `jump loopend`, or conditional, like `if x == 0 jump loopend`), or a no-op.

The interpreter is implemented with a two-pass approach. The first pass is an analysis pass using ANTLR’s listener interface. In addition to doing some program validation, this pass has two important roles: generating a list of instructions, and identifying the instruction that each label refers to.

The second pass is the actual interpreter, and it uses ANTLR’s visitor pattern. We have to use a visitor instead of a listener because we need more control over how the tree gets walked. In fact, instead of walking the tree provided by ANTLR, the interpreter visits the first instruction in the list of instructions generated by the analysis pass. If an instruction is a jump, the visitor returns the index of the next instruction to execute. Otherwise, the instructions are executed in order, updating the environment along the way.

As it exists right now, there is no overall value for a program - the tests work by looking at the value of a specific variable inside the environment. Once function parameters and returns are added, however, the value for the program can be the outermost return value.

## What’s Next
Several major features are missing. The two biggest ones are proper support for functions and some sort of memory system. I didn’t realize it until after writing most of this section, but these are actually intimately related in that they both require committing to a runtime system, in a way that the currently supported operations do not.

### Functions
Functions will be implemented with 3 new operators:
- `call <fn_name>, <param_count>`, which actually calls the function
- `return <value>`, which transfers control back to the caller and returns a value
- `param <value>`, which specifies arguments to a function call. If it’s used  on the right-hand side of an assignment, it will pop the parameter off the parameter stack. If it’s used on its own, it will push the given value onto the parameter stack. Alternatively, you could specify parameter positions, like `param 0 <value>`. I haven’t decided yet how to implement this exact feature, but either should work just fine.

Here’s a sample program of a function that doubles its input:

```
param 5
result = call double 1
jump end
double: x = param
y = x + x
return y
end: return result
```

Note that this introduces some potential complications. For example, consider the following implementation of the factorial function:

```
param 5
result = call factorial 1
jump end
factorial: n = param
if n <= 1 jump basecase
sub1 = n - 1
param sub1
factsub1 = call factorial 1
res = n * factsub1
return res
basecase: return 1
end: noop
```

If implemented naively, this function will always return 1! Because there is not currently any separate scoping for functions, n is going to be updated globally every time this function is called. Therefore, by the time we reach the line `res = n * factsub1`, n will always be 1.

To resolve this, we need a stack to track function calls and introduce new scopes to support local variables. Of course, that comes with problems in updating global variables, but I’ll leave that discussion for later.

### Memory Operations
To support the full set of features I want, I need to provide some sort of memory, and allow indexed access to memory. Here are the types of operations I might want to support:

```
x = y[1]
x[3] = 5
x = *y
*x = 5
```

While adding functions is a change in the flow of the interpreter, adding these memory operations requires a significant change in how values are stored in the interpreter. I had initially planned on offering something like the `&` operator in C, but I’m reluctant to allow that for arbitrary variables. Consider the following program:

```
x = 5
y = &x
*y = 7
```

The second line is a little awkward, given our current representation of an environment as a Python dict. What is the value contained in y? Despite the second line not really making sense, the 3rd line is actually totally reasonable! It should set the value contained in x to 7. However, it makes sense because we’re able to optimize it away in our heads, knowing that `*&x` is equivalent to just `x`. The problem is that offering the address-of operator requires separating names from their values, which is perhaps more trouble than it’s worth, at least for now.

Instead of offering a general-purpose address-of operator, I’m considering instead providing some sort of allocation function that can request a chunk of memory. To avoid confusion with C’s `alloc`, I’ll probably name it something like `memrequest`, which will allocate chunks of memory for the program. For example, this is a memoized program for determining the 10th number in the Fibonacci sequence. (Note that I haven’t tested this, since the memory operations don’t yet exist, so there might be bugs.)

```
n = 10
fibs = memrequest n
i = 0
fib: if i >= n jump fibend
if i == 0 jump if0
if i == 1 jump if1
tmp1 = i - 1
tmp2 = i - 2
prev1 = fibs[tmp1]
prev2 = fibs[tmp2]
fibs[i] = prev1 + prev2
jump ifend
if0: fibs[0] = 0
jump ifend
if1: fibs[1] = 1  # fall through to ifend
ifend: i = i + 1
jump fib
fibend: result = fibs[i
```

`memrequest`would support constructs like structs and arrays without requiring extensive changes elsewhere in the interpreter. However, if implementing function calls will require more explicit memory constructs anyway, it might be worth it to just give every variable an address and support `&` directly.
